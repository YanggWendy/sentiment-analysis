{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanggWendy/sentiment-analysis/blob/main/instruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u-Pk-Xb5UJH"
      },
      "source": [
        "# Instructions for Project 1 - Sentiment Analysis\n",
        "\n",
        "Hello everyone, this is Quyet. I am glad to host the first project. My email is *vqdo@connect.ust.hk*. Feel free to send me an email if you have any problem regarding this project.\n",
        "\n",
        "In this project, you will try to work on a sentiment analysis task.\n",
        "You will build a model to predict the scores (a.k.a. the \"stars\" column in datasets, from 1 to 5) of each review.\n",
        "For each review, you are given a piece of text as well as some other features (Explore yourself! You may look at the columns of the data).\n",
        "You can consider the predicted variables as categorical, ordinal or numerical.\n",
        "\n",
        "Just a kind note: The codes and techniques introduced in the previous tutorials may come in handy. You can refer to the .ipynb notebooks for details.\n",
        "\n",
        "## Important dates, submission requirements and grading policy \n",
        "**Important dates:**\n",
        "- *March 16, 2023 (Thursday)*: Project starts\n",
        "- *March 23, 2023 (Thursday)*: Release the validation score of a weak baseline\n",
        "- *March 30, 2023 (Thursday)* Release the validation score of a strong baseline\n",
        "- *April 13, 2023, 23:59 (Thursday)*: `Submission Deadline`\n",
        "\n",
        "**Submission requirements:**  \n",
        "Each team leader is required to submit the groupNo.zip file in the Canvas. It shoud contain \n",
        "- `pred.csv`: Predictions on test data (please make sure you can successfully evaluate your validation predictions on the validation data with the help of evaluate.py). The file should contain two so-called columns, which are `review_id`\n",
        "and `stars`.\n",
        "- report (1-2 pages of pdf)\n",
        "- code (Frameworks and programming languages are not restricted)\n",
        "\n",
        "**Grading policy:**  \n",
        "We will check your report with your code and your model performance (in terms of macro F1) on the test set.\n",
        "\n",
        "| Grade | Classifier (80%)                                                   | Report (20%)                      |\n",
        "|-------|--------------------------------------------------------------------|-----------------------------------|\n",
        "| 50%   | example code in tutorials or in Project 1 without any modification | submission                        |\n",
        "| 60%   | an easy baseline that most students can outperform                 | algorithm you used                |\n",
        "| 80%   | a competitive baseline that about half students can surpass        | detailed explanation              |\n",
        "| 90%   | a very competitive baseline without any special mechanism          | detailed explanation and analysis, such as explorative data analysis and ablation study |\n",
        "| 100%  | a very competitive baseline with at least one mechanism            | excellent ideas, detailed explanation and solid analysis |\n",
        "\n",
        "\n",
        "\n",
        "## Instruction Content\n",
        "In this notebook, you are provided with the code snippets to start with.\n",
        "\n",
        "The content follows previous lectures and tutorials. But some potentially useful python packages are also mentioned.\n",
        "\n",
        "1. Loading data and saving predictions\n",
        "    1. Loading data\n",
        "    1. Saving predictions to file\n",
        "1. Preprocessing\n",
        "    1. Text data processing recap\n",
        "    1. Explorative data analysis\n",
        "1. Learning Baselines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDERNAME = 'comp4332/Project 1/'\n",
        "assert FOLDERNAME is not None, \"[1]Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXlmVvr91sAI",
        "outputId": "d49d6fdd-579e-49b6-e1e4-a924e3bb3132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/comp4332/Project 1/data'"
      ],
      "metadata": {
        "id": "jPyxxXHQ5hdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading data and saving predictions\n",
        "\n",
        "The same as previous tutorials, we use `pandas` as the basic tool to load & dump the data.\n",
        "The key ingredient of our operation is the `DataFrame` in pandas."
      ],
      "metadata": {
        "id": "cpoRui_47pOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56Yveell5UJM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTxx0LA366mu",
        "outputId": "cd989da1-bd0d-424d-8d3b-37d57662a63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you use Google Colab, un-comment this cell, modify `path_to_data` if needed, and run to mount data to `data`\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# path_to_data = '/content/drive/MyDrive/HKUST stuff/COMP4332_Project1/data'\n",
        "# !rm -f data\n",
        "# !ln -s '/content/drive/MyDrive/HKUST stuff/COMP4332_Project1/data' data"
      ],
      "metadata": {
        "id": "V9e5rcOs77K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo8Z7VVq5UJO"
      },
      "source": [
        "### A. Loading data\n",
        "\n",
        "The following code shows how to load the datasets for this project.  \n",
        "Among which, we do not release the labels (the \"stars\" column) for the test set. \n",
        "You may evaluate your trained model on the validation set instead.\n",
        "However, your submitted predictions (``pred.csv``) should be generated on the test set.\n",
        "\n",
        "Each year we release different data, so old models are not guaranteed to solve the new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coz-oCwS5UJP"
      },
      "outputs": [],
      "source": [
        "def load_data(split_name='train', columns=['text', 'stars'], folder='data'):\n",
        "    '''\n",
        "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
        "        \n",
        "        You may also specify the column names to load any columns in the .csv data file.\n",
        "        Among many, \"text\" can be used as model input, and \"stars\" column is the labels (sentiment). \n",
        "        If you like, you are free to use columns other than \"text\" for prediction.\n",
        "    '''\n",
        "    try:\n",
        "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
        "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
        "        df = df.loc[:,columns]\n",
        "        print(\"Success\")\n",
        "        return df\n",
        "    except:\n",
        "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
        "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJnx8k_s5UJQ"
      },
      "source": [
        "Then you can extract the data by specifying the desired split and columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEJmxylT5UJR",
        "outputId": "70f7aadd-42d3-4ab3-8daf-0236a3543e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select [text, stars] columns from the train split\n",
            "Success\n",
            "select [text, stars] columns from the valid split\n",
            "Success\n",
            "select [text, stars] columns from the test split\n",
            "Failed loading specified columns... Returning all columns from the test split\n"
          ]
        }
      ],
      "source": [
        "train_df = load_data('train', columns=['text', 'stars'], folder='/content/drive/MyDrive/comp4332/Project 1/data')\n",
        "valid_df = load_data('valid', columns=['text', 'stars'], folder='/content/drive/MyDrive/comp4332/Project 1/data')\n",
        "# the test set labels (the 'stars' column) are not available! So the following code will instead return all columns\n",
        "test_df = load_data('test', columns=['text', 'stars'], folder='/content/drive/MyDrive/comp4332/Project 1/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TuA-yimg5UJS",
        "outputId": "d9ce2882-d8dd-4f2e-c1ff-c70137869805"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  stars\n",
              "0  Best Sunday buffet in the two cities of Charlo...      5\n",
              "1  My friends and I decided to check out this pla...      4\n",
              "2  This is definitely New York Chinese food! The ...      5\n",
              "3  Beaucoup moins de choix que son voisin d'en fa...      3\n",
              "4  Location is nice, but it is the typical blah H...      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e279c160-8756-4b2e-895e-cb4e7334de24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Best Sunday buffet in the two cities of Charlo...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My friends and I decided to check out this pla...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is definitely New York Chinese food! The ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beaucoup moins de choix que son voisin d'en fa...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Location is nice, but it is the typical blah H...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e279c160-8756-4b2e-895e-cb4e7334de24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e279c160-8756-4b2e-895e-cb4e7334de24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e279c160-8756-4b2e-895e-cb4e7334de24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZKc0Sllc5UJS",
        "outputId": "93c4e6be-7838-435f-d5e3-795f16d2bb53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id  cool                 date  funny  \\\n",
              "0  V-qDa2kr5qWdhs7PU-l-3Q     0           2013-05-29      0   \n",
              "1  C1zlvNlxlGZB8g0162QslQ     0  2012-03-02 15:51:49      0   \n",
              "2  0FOON_PNvG0ZxIZh6Jcv2A     0  2013-09-24 20:31:37      0   \n",
              "3  r49iBfbnfoK7yt4rdsL_7g     0  2018-10-20 01:34:08      0   \n",
              "4  xnLNPkL7bbdhD842T4oPqg     0           2016-09-25      1   \n",
              "\n",
              "                review_id                                               text  \\\n",
              "0  fBHWLNEJmhk6AkzmfLwWcw  Would like to give this more stars - usually I...   \n",
              "1  ldEQ02aP1OeSa5N2beseNg  My wife and I took some friends here after din...   \n",
              "2  0oGr6v9VjtRsRsROGMoWTA  My husband and I had lunch here for the first ...   \n",
              "3  eg5eJ5HmqXuzkxucnKvMTw  I love coming here with my friends! Great for ...   \n",
              "4  BNDAe34Mxj--Brkzcfi4QA  Make sure that you double check how much these...   \n",
              "\n",
              "   useful                 user_id  \n",
              "0       1  1pigoFijaHVWGrQl1_tYjw  \n",
              "1       0  BKWPuPZFcGmgjRFRzoq1pw  \n",
              "2       0  BYVYXKqNs-vv-N1ZhRMs0g  \n",
              "3       2  dpzmyNglDMeTgV3T5ylUSQ  \n",
              "4       1  yk9wx31bfMEe_IXB8Q-ylA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbbf76c4-c0b8-4b5a-b858-bc485e21eb8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>V-qDa2kr5qWdhs7PU-l-3Q</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-05-29</td>\n",
              "      <td>0</td>\n",
              "      <td>fBHWLNEJmhk6AkzmfLwWcw</td>\n",
              "      <td>Would like to give this more stars - usually I...</td>\n",
              "      <td>1</td>\n",
              "      <td>1pigoFijaHVWGrQl1_tYjw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C1zlvNlxlGZB8g0162QslQ</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-03-02 15:51:49</td>\n",
              "      <td>0</td>\n",
              "      <td>ldEQ02aP1OeSa5N2beseNg</td>\n",
              "      <td>My wife and I took some friends here after din...</td>\n",
              "      <td>0</td>\n",
              "      <td>BKWPuPZFcGmgjRFRzoq1pw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0FOON_PNvG0ZxIZh6Jcv2A</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-09-24 20:31:37</td>\n",
              "      <td>0</td>\n",
              "      <td>0oGr6v9VjtRsRsROGMoWTA</td>\n",
              "      <td>My husband and I had lunch here for the first ...</td>\n",
              "      <td>0</td>\n",
              "      <td>BYVYXKqNs-vv-N1ZhRMs0g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>r49iBfbnfoK7yt4rdsL_7g</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-10-20 01:34:08</td>\n",
              "      <td>0</td>\n",
              "      <td>eg5eJ5HmqXuzkxucnKvMTw</td>\n",
              "      <td>I love coming here with my friends! Great for ...</td>\n",
              "      <td>2</td>\n",
              "      <td>dpzmyNglDMeTgV3T5ylUSQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xnLNPkL7bbdhD842T4oPqg</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09-25</td>\n",
              "      <td>1</td>\n",
              "      <td>BNDAe34Mxj--Brkzcfi4QA</td>\n",
              "      <td>Make sure that you double check how much these...</td>\n",
              "      <td>1</td>\n",
              "      <td>yk9wx31bfMEe_IXB8Q-ylA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbbf76c4-c0b8-4b5a-b858-bc485e21eb8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbbf76c4-c0b8-4b5a-b858-bc485e21eb8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbbf76c4-c0b8-4b5a-b858-bc485e21eb8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFfewsiX5UJT",
        "outputId": "143e535b-03f8-4e5b-e7f9-0dea19946465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18000 2000 4000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df), len(valid_df), len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mef_BG-X5UJT"
      },
      "source": [
        "### B. Saving predictions to file\n",
        "\n",
        "Your submitted predictions are supposed to be a .csv file containing two columns, i.e. (``review_id`` and ``stars``). \n",
        "\n",
        "Here, as an example, we generate some random predictions as our answer, which are put in a DataFrame and output to a .csv file\n",
        "\n",
        "After getting your model predictions on the test set, you may follow these steps to generate your ``pred.csv`` file. (By replacing the random predictions with your model predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AmFZ96x5UJU"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwYfkZvU5UJU"
      },
      "outputs": [],
      "source": [
        "random_pred = pd.DataFrame(data={\n",
        "    'review_id': test_df['review_id'],\n",
        "    'stars': np.random.randint(0, 6, size=len(test_df))\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jGGl8Kt85UJU",
        "outputId": "7154ae16-5024-41ce-c32c-34ae6a4f8c16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                review_id  stars\n",
              "0  fBHWLNEJmhk6AkzmfLwWcw      0\n",
              "1  ldEQ02aP1OeSa5N2beseNg      4\n",
              "2  0oGr6v9VjtRsRsROGMoWTA      4\n",
              "3  eg5eJ5HmqXuzkxucnKvMTw      5\n",
              "4  BNDAe34Mxj--Brkzcfi4QA      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0d673a7-856a-49ab-bce2-c52075398b14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fBHWLNEJmhk6AkzmfLwWcw</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ldEQ02aP1OeSa5N2beseNg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0oGr6v9VjtRsRsROGMoWTA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eg5eJ5HmqXuzkxucnKvMTw</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BNDAe34Mxj--Brkzcfi4QA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0d673a7-856a-49ab-bce2-c52075398b14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0d673a7-856a-49ab-bce2-c52075398b14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0d673a7-856a-49ab-bce2-c52075398b14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "random_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMBpLyd35UJU"
      },
      "outputs": [],
      "source": [
        "random_pred.to_csv(f'random_pred.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb1ZhmEZ5UJV"
      },
      "source": [
        "Then, you will get a ``random_pred.csv`` in your folder."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocessing\n",
        "\n",
        "Here are some preprocessing examples for your reference. For more details you may refer to the previous tutorials."
      ],
      "metadata": {
        "id": "n7lkS6sqAIT0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luZkHLq35UJV"
      },
      "source": [
        "### A. Text data processing recap\n",
        "In the tutorials, we have shown how to extract textual features using the `nltk` package\n",
        "\n",
        "Remember to use the NLTK Downloader to obtain the resource first:\n",
        "```\n",
        "  >>> import nltk\n",
        "  >>> nltk.download('stopwords')\n",
        "  >>> nltk.download('punkt')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-KE25vc5UJV"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def lower(s):\n",
        "    \"\"\"\n",
        "    :param s: a string.\n",
        "    return a string with lower characters\n",
        "    Note that we allow the input to be nested string of a list.\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: 'text mining is to identify useful information.'\n",
        "    \"\"\"\n",
        "    if isinstance(s, list):\n",
        "        return [lower(t) for t in s]\n",
        "    if isinstance(s, str):\n",
        "        return s.lower()\n",
        "    else:\n",
        "        raise NotImplementedError(\"unknown datatype\")\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param text: a doc with multiple sentences, type: str\n",
        "    return a word list, type: list\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "def stem(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of stemmed words, type: list\n",
        "    e.g.\n",
        "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     results.append(ps.stem(token))\n",
        "    # return results\n",
        "\n",
        "    return [ps.stem(token) for token in tokens]\n",
        "\n",
        "def n_gram(tokens, n=1):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    :param n: the corresponding n-gram, type: int\n",
        "    return a list of n-gram tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
        "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
        "    \"\"\"\n",
        "    if n == 1:\n",
        "        return tokens\n",
        "    else:\n",
        "        results = list()\n",
        "        for i in range(len(tokens)-n+1):\n",
        "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
        "            results.append(\" \".join(tokens[i:i+n]))\n",
        "        return results\n",
        "\n",
        "def filter_stopwords(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of filtered tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     if token not in stopwords and not token.isnumeric():\n",
        "    #         results.append(token)\n",
        "    # return results\n",
        "\n",
        "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_onehot_vector(feats, feats_dict):\n",
        "    \"\"\"\n",
        "    :param data: a list of features, type: list\n",
        "    :param feats_dict: a dict from features to indices, type: dict\n",
        "    return a feature vector,\n",
        "    \"\"\"\n",
        "    # initialize the vector as all zeros\n",
        "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
        "    for f in feats:\n",
        "        # get the feature index, return -1 if the feature is not existed\n",
        "        f_idx = feats_dict.get(f, -1)\n",
        "        if f_idx != -1:\n",
        "            # set the corresponding element as 1\n",
        "            vector[f_idx] = 1\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeAOeeYC5UJW"
      },
      "source": [
        "Note that you can use the `map` function to apply your preprocessing functions into the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hei6VERQ5UJW",
        "outputId": "b7c1d735-40bf-4c03-c96f-f12dc38ef5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [would, like, give, stars, -, usually, i, get,...\n",
            "1    [my, wife, i, took, friends, dinner, advise, a...\n",
            "2    [my, husband, i, lunch, first, time, years, .,...\n",
            "3    [i, love, coming, friends, !, great, groups, o...\n",
            "4    [make, sure, double, check, much, guys, chargi...\n"
          ]
        }
      ],
      "source": [
        "test_df['tokens'] = test_df['text'].map(tokenize).map(filter_stopwords).map(lower)\n",
        "print(test_df['tokens'].head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2aF74qi5UJW"
      },
      "source": [
        "Besides `nltk`, `SpaCy` may also be useful.\n",
        "\n",
        "You can explore it at https://spacy.io/\n",
        "\n",
        "Let's install it with the following command (in terminal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTFX-QsE5UJX"
      },
      "source": [
        "```bash\n",
        "python -m pip install spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGU6YJjN5UJX"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCLmErA45UJX"
      },
      "source": [
        "You may use spacy to extract linguistic features from texts\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZz4vWC85UJX",
        "outputId": "6198e6b8-8c96-4a08-d603-aa50df9e15f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw       ,\t stem      ,\t PartOfSpeech,\t dependency,\t shape     ,\t is alpha  ,\t is stop   ,\t its childrens in the parsing tree,\t \n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Apple     ,\t Apple     ,\t PROPN     ,\t nsubj     ,\t Xxxxx     ,\t True      ,\t False     ,\t []        ,\t \n",
            "is        ,\t be        ,\t AUX       ,\t aux       ,\t xx        ,\t True      ,\t True      ,\t []        ,\t \n",
            "looking   ,\t look      ,\t VERB      ,\t ROOT      ,\t xxxx      ,\t True      ,\t False     ,\t [Apple, is, at, startup],\t \n",
            "at        ,\t at        ,\t ADP       ,\t prep      ,\t xx        ,\t True      ,\t True      ,\t [buying]  ,\t \n",
            "buying    ,\t buy       ,\t VERB      ,\t pcomp     ,\t xxxx      ,\t True      ,\t False     ,\t [U.K.]    ,\t \n",
            "U.K.      ,\t U.K.      ,\t PROPN     ,\t dobj      ,\t X.X.      ,\t False     ,\t False     ,\t []        ,\t \n",
            "startup   ,\t startup   ,\t NOUN      ,\t dep       ,\t xxxx      ,\t True      ,\t False     ,\t [for]     ,\t \n",
            "for       ,\t for       ,\t ADP       ,\t prep      ,\t xxx       ,\t True      ,\t True      ,\t [billion] ,\t \n",
            "$         ,\t $         ,\t SYM       ,\t quantmod  ,\t $         ,\t False     ,\t False     ,\t []        ,\t \n",
            "1         ,\t 1         ,\t NUM       ,\t compound  ,\t d         ,\t False     ,\t False     ,\t []        ,\t \n",
            "billion   ,\t billion   ,\t NUM       ,\t pobj      ,\t xxxx      ,\t True      ,\t False     ,\t [$, 1]    ,\t \n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "fmt = \"{:10s},\\t \" * 8\n",
        "print(fmt.format('raw', 'stem', 'PartOfSpeech', 'dependency', 'shape', 'is alpha', 'is stop', 'its childrens in the parsing tree'))\n",
        "print('-'*140)\n",
        "for token in doc:\n",
        "    print(fmt.format(token.text, token.lemma_, token.pos_, token.dep_,\n",
        "            token.shape_, str(token.is_alpha), str(token.is_stop), str(list(token.children))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9y6cC-m5UJX"
      },
      "source": [
        "SpaCy also allows you to use the embeddings for both sentence and words\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQXuIT-i5UJY",
        "outputId": "8c6d9d59-0185-4aa0-d48c-00f69011fc47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple is looking at buying U.K. startup for $1 billion [-0.49226806  0.4047865   0.5446301   0.26508954  0.55884624] ...\n",
            "Apple [-1.2311022  -1.1917267   0.15840432  0.35988146  0.6805324 ] ...\n",
            "is [-1.002091   -0.24935624  0.2847826   0.7584362  -0.5807617 ] ...\n",
            "looking [-0.34237027  1.066651    0.7334784   0.09219186 -1.0159136 ] ...\n",
            "at [ 1.4327703   1.965018    0.5286215  -1.1037531  -0.29277685] ...\n",
            "buying [ 0.21374063  0.9700631  -0.3710441   0.25935942 -0.52812344] ...\n",
            "U.K. [-0.4769047  -0.68812644 -1.0802059   0.9870316   1.3138592 ] ...\n",
            "startup [-0.76879835  0.16186565  0.20556125 -0.70368016 -0.5637021 ] ...\n",
            "for [-0.12732005  0.20830444  1.3329197  -0.43356487 -0.78245395] ...\n",
            "$ [-0.5493659   1.2996751   0.19532189  0.4663917   1.8706083 ] ...\n",
            "1 [-1.1942625   0.78716505  5.5716743   0.19170302  3.1280797 ] ...\n",
            "billion [-1.3692441   0.12311834 -1.5685828   2.041988    2.9179604 ] ...\n"
          ]
        }
      ],
      "source": [
        "print(doc, doc.vector[:5], '...')\n",
        "for t in doc:\n",
        "    print(t, t.vector[:5], '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFBq_0Xe5UJY"
      },
      "source": [
        "For more usage of SpaCy, you can refer to its documentation at this link: https://spacy.io/usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAFJ4e4O5UJY"
      },
      "source": [
        "### B. Explorative data analysis\n",
        "\n",
        "For our dataset, there are features more than texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ylzjrnj5UJY",
        "outputId": "abd3bbe5-7b02-47d4-87bd-d6b429daec3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select [f, u, l, l] columns from the train split\n",
            "Failed loading specified columns... Returning all columns from the train split\n"
          ]
        }
      ],
      "source": [
        "train_df_full = load_data('train', columns='full',folder= path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "lNEZqWgo5UJY",
        "outputId": "c75242b0-e2b5-45d9-ad91-12f2d8f3f2a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id  cool                 date  funny  \\\n",
              "0  JYgoAQHdJWKPArQDvBEBng     0  2016-03-30 21:40:34      0   \n",
              "1  AASa5G_OHCxGQ0tbjT_2tw     0  2018-08-30 02:50:46      0   \n",
              "2  Z2xuK4BbrD0Qr9dAs7oTVw     0           2017-02-20      0   \n",
              "3  YAMXCiebYV49_B8lDAaLxA     0  2017-04-06 21:56:41      0   \n",
              "4  ynvp3qvt3xc321dLKFxpgA     0  2012-03-09 19:30:47      0   \n",
              "\n",
              "                review_id  stars  \\\n",
              "0  JlUcJiIy24pw5jStCLtavg      5   \n",
              "1  xJBrURoI6Tm7PCmytXUMyg      4   \n",
              "2  99wD_l4D6Sw7Kesaq9GPhg      5   \n",
              "3  AmNFz9svFx9QCSZsUs8JTA      3   \n",
              "4  nwnlKZN2MWhyL3aKUqY7ig      2   \n",
              "\n",
              "                                                text  useful  \\\n",
              "0  Best Sunday buffet in the two cities of Charlo...       1   \n",
              "1  My friends and I decided to check out this pla...       0   \n",
              "2  This is definitely New York Chinese food! The ...       4   \n",
              "3  Beaucoup moins de choix que son voisin d'en fa...       0   \n",
              "4  Location is nice, but it is the typical blah H...       2   \n",
              "\n",
              "                  user_id  \n",
              "0  SxLNrLxHm0aEw-kLrbPLew  \n",
              "1  aW22TlXwhkUUqBYFG7fbTA  \n",
              "2  SerdK2DW_2R7z1b9WU97fg  \n",
              "3  pf4nr7_PlMrHjbmQYbEFcQ  \n",
              "4  Mf5TQEqn59k_TapTpfjYdA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edfe8894-910e-4f17-8ac0-8fbac5019c4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JYgoAQHdJWKPArQDvBEBng</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-03-30 21:40:34</td>\n",
              "      <td>0</td>\n",
              "      <td>JlUcJiIy24pw5jStCLtavg</td>\n",
              "      <td>5</td>\n",
              "      <td>Best Sunday buffet in the two cities of Charlo...</td>\n",
              "      <td>1</td>\n",
              "      <td>SxLNrLxHm0aEw-kLrbPLew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AASa5G_OHCxGQ0tbjT_2tw</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-08-30 02:50:46</td>\n",
              "      <td>0</td>\n",
              "      <td>xJBrURoI6Tm7PCmytXUMyg</td>\n",
              "      <td>4</td>\n",
              "      <td>My friends and I decided to check out this pla...</td>\n",
              "      <td>0</td>\n",
              "      <td>aW22TlXwhkUUqBYFG7fbTA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Z2xuK4BbrD0Qr9dAs7oTVw</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-02-20</td>\n",
              "      <td>0</td>\n",
              "      <td>99wD_l4D6Sw7Kesaq9GPhg</td>\n",
              "      <td>5</td>\n",
              "      <td>This is definitely New York Chinese food! The ...</td>\n",
              "      <td>4</td>\n",
              "      <td>SerdK2DW_2R7z1b9WU97fg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>YAMXCiebYV49_B8lDAaLxA</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-04-06 21:56:41</td>\n",
              "      <td>0</td>\n",
              "      <td>AmNFz9svFx9QCSZsUs8JTA</td>\n",
              "      <td>3</td>\n",
              "      <td>Beaucoup moins de choix que son voisin d'en fa...</td>\n",
              "      <td>0</td>\n",
              "      <td>pf4nr7_PlMrHjbmQYbEFcQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ynvp3qvt3xc321dLKFxpgA</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-03-09 19:30:47</td>\n",
              "      <td>0</td>\n",
              "      <td>nwnlKZN2MWhyL3aKUqY7ig</td>\n",
              "      <td>2</td>\n",
              "      <td>Location is nice, but it is the typical blah H...</td>\n",
              "      <td>2</td>\n",
              "      <td>Mf5TQEqn59k_TapTpfjYdA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edfe8894-910e-4f17-8ac0-8fbac5019c4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-edfe8894-910e-4f17-8ac0-8fbac5019c4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-edfe8894-910e-4f17-8ac0-8fbac5019c4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_df_full.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmVqQgbi5UJZ"
      },
      "source": [
        "You can explore the relationship between different features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0SGk2KU5UJZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "hJDKkHCA5UJZ",
        "outputId": "ab52aa6e-ba0e-40e6-ffbe-a6c61f2d86a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f1d82ce0b20>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.scatter(train_df_full['cool'], train_df_full['funny'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "Vw222MP85UJZ",
        "outputId": "9be393c4-018b-4c8d-92d6-862773a57241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2659., 1426., 1969., 4008., 7938.]),\n",
              " array([1. , 1.8, 2.6, 3.4, 4.2, 5. ]),\n",
              " <BarContainer object of 5 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(train_df_full['stars'], bins=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40p-kY_J5UJa"
      },
      "source": [
        "Moreover, you may use the id feature to aggregate data samples\n",
        "\n",
        "For example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "d_gWUZd15UJa",
        "outputId": "b7e75673-3575-45d9-a727-e0086cc456cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  business_id  funny  cool  stars\n",
            "654    --9e1ONYQuAa-CB_Rrw7Tw      3     9      4\n",
            "3248   --9e1ONYQuAa-CB_Rrw7Tw      0     2      4\n",
            "12008  --9e1ONYQuAa-CB_Rrw7Tw      0     0      3\n",
            "12769  --9e1ONYQuAa-CB_Rrw7Tw      0     1      4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for bid, sub_df in train_df_full.groupby('business_id'):\n",
        "    if len(sub_df) > 1:\n",
        "        print(sub_df[['business_id', 'funny', 'cool', 'stars']].head())\n",
        "        plt.hist(sub_df['stars'], bins=5)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttBTnBmh5UJa",
        "outputId": "ea78b324-407c-4e1e-e8eb-e271da234d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      user_id  funny  cool  stars\n",
            "8730   -0HhZbPBlB1YZx3BhAfaEA      0     0      4\n",
            "16969  -0HhZbPBlB1YZx3BhAfaEA      2     2      5\n"
          ]
        }
      ],
      "source": [
        "for bid, sub_df in train_df_full.groupby('user_id'):\n",
        "    if len(sub_df) > 1:\n",
        "        print(sub_df[['user_id', 'funny', 'cool', 'stars']].head())\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75a7A16B5UJa"
      },
      "source": [
        "## 3. Baselines\n",
        "\n",
        "Finally, we provide two example baselines for your reference. The first baseline extracts TF-iDF features from texts and use logistic regression to generate prediction. The second baseline uses Convolutional Neural Networks (CNNs) to generate prediction from texts.\n",
        "\n",
        "\n",
        "We only use ''text'' data here, and only consider its first 5k training samples. It is just an example, you can use the data as you like."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF + LR"
      ],
      "metadata": {
        "id": "lpeYkRdXAOHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8XXemtF5UJa"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5AKPx2A5UJb",
        "outputId": "a96805d3-f68f-4789-d948-e38a0f107af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select [text, stars] columns from the train split\n",
            "Success\n",
            "select [text, stars] columns from the valid split\n",
            "Success\n"
          ]
        }
      ],
      "source": [
        "train_df = load_data('train',folder=path)[:5000]\n",
        "valid_df = load_data('valid',folder=path)\n",
        "x_train = train_df['text']\n",
        "y_train = train_df['stars']\n",
        "x_valid = valid_df['text']\n",
        "y_valid = valid_df['stars']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NooKm1m75UJb",
        "outputId": "0be45aa8-59ea-482d-cd81-b389ea55dd97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=[('tfidf',\n",
            "                 TfidfVectorizer(tokenizer=<function tokenize at 0x7f1f1713bc10>)),\n",
            "                ('lr', LogisticRegression())])\n"
          ]
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
        "lr = LogisticRegression()\n",
        "steps = [('tfidf', tfidf),('lr', lr)]\n",
        "pipe = Pipeline(steps)\n",
        "print(pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "Xrav6WYa5UJb",
        "outputId": "7ab60342-1771-40d7-fb46-1d0c92cc271d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(tokenizer=<function tokenize at 0x7f1f1713bc10>)),\n",
              "                ('lr', LogisticRegression())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x7f1f1713bc10&gt;)),\n",
              "                (&#x27;lr&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x7f1f1713bc10&gt;)),\n",
              "                (&#x27;lr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function tokenize at 0x7f1f1713bc10&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "pipe.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjSUgqGJ5UJb",
        "outputId": "88aa3d83-549c-49f7-b0ce-629348f48798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.69      0.77      0.73       292\n",
            "           2       0.45      0.09      0.14       163\n",
            "           3       0.44      0.16      0.23       232\n",
            "           4       0.44      0.42      0.43       421\n",
            "           5       0.70      0.90      0.79       892\n",
            "\n",
            "    accuracy                           0.63      2000\n",
            "   macro avg       0.54      0.47      0.46      2000\n",
            "weighted avg       0.59      0.63      0.59      2000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[225   7  10  11  39]\n",
            " [ 67  14  18  40  24]\n",
            " [ 19   8  36 105  64]\n",
            " [  7   2  13 178 221]\n",
            " [  9   0   4  74 805]]\n",
            "accuracy 0.629\n"
          ]
        }
      ],
      "source": [
        "y_pred = pipe.predict(x_valid)\n",
        "print(classification_report(y_valid, y_pred))\n",
        "print(\"\\n\\n\")\n",
        "print(confusion_matrix(y_valid, y_pred))\n",
        "print('accuracy', np.mean(y_valid == y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "Tb9nzPhQGfIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary packages and libaries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm, datasets\n",
        "from itertools import chain\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "EEgoqu7TGt6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feats_dict(feats, min_freq=-1, max_freq=-1, max_size=-1):\n",
        "    \"\"\"\n",
        "    :param data: a list of features, type: list(list)\n",
        "    :param min_freq: the lowest fequency that the fequency of a feature smaller than it will be filtered out, type: int\n",
        "    :param max_freq: the highest fequency that the fequency of a feature larger than it will be filtered out, type: int\n",
        "    :param max_size: the max size of feature dict, type: int\n",
        "    return a feature dict that maps features to indices, sorted by frequencies\n",
        "    # Counter document: https://docs.python.org/3.6/library/collections.html#collections.Counter\n",
        "    \"\"\"\n",
        "    # count all features\n",
        "    feat_cnt = Counter(feats) # [\"text\", \"text\", \"mine\"] --> {\"text\": 2, \"mine\": 1}\n",
        "    if max_size > 0 and min_freq == -1 and max_freq == -1:\n",
        "        valid_feats = [f for f, cnt in feat_cnt.most_common(max_size)]\n",
        "    else:\n",
        "        valid_feats = list()\n",
        "        for f, cnt in feat_cnt.most_common():\n",
        "            if (min_freq == -1 or cnt >= min_freq) and \\\n",
        "                (max_freq == -1 or cnt <= max_freq):\n",
        "                valid_feats.append(f)\n",
        "    if max_size > 0 and len(valid_feats) > max_size:\n",
        "        valid_feats = valid_feats[:max_size]        \n",
        "    print(\"Size of features:\", len(valid_feats))\n",
        "    \n",
        "    # build a mapping from features to indices\n",
        "    feats_dict = dict(zip(valid_feats, range(len(valid_feats))))\n",
        "    return feats_dict\n",
        "\n",
        "def get_onehot_vector(feats, feats_dict):\n",
        "    \"\"\"\n",
        "    :param feats: a list of features, type: list\n",
        "    :param feats_dict: a dict from features to indices, type: dict\n",
        "    return a feature vector,\n",
        "    \"\"\"\n",
        "    # initialize the vector as all zeros\n",
        "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
        "    for f in feats:\n",
        "        # get the feature index, return -1 if the feature is not existed\n",
        "        f_idx = feats_dict.get(f, -1)\n",
        "        if f_idx != -1:\n",
        "            # set the corresponding element as 1\n",
        "            vector[f_idx] = 1\n",
        "    return vector"
      ],
      "metadata": {
        "id": "ftoO2uOCIcpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "train_df = load_data('train',folder=path)[:5000]\n",
        "valid_df = load_data('valid',folder=path)\n",
        "x_train = train_df['text']\n",
        "y_train = train_df['stars']\n",
        "x_valid = valid_df['text']\n",
        "y_valid = valid_df['stars']\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "O-w5P2rYIBVY",
        "outputId": "d90286c2-31a1-4a4b-9796-90882ab4d699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrain_df = load_data('train',folder=path)[:5000]\\nvalid_df = load_data('valid',folder=path)\\nx_train = train_df['text']\\ny_train = train_df['stars']\\nx_valid = valid_df['text']\\ny_valid = valid_df['stars']\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract features\n",
        "train_tokens = [tokenize(text) for text in x_train]\n",
        "test_tokens = [tokenize(text) for text in x_valid]\n",
        "\n",
        "train_stemmed = [stem(tokens) for tokens in x_train]\n",
        "test_stemmed = [stem(tokens) for tokens in x_valid]\n",
        "\n",
        "train_stemmed = [filter_stopwords(tokens) for tokens in train_stemmed]\n",
        "test_stemmed = [filter_stopwords(tokens) for tokens in test_stemmed]\n",
        "\n",
        "train_2_gram = [n_gram(tokens, 2) for tokens in train_stemmed]\n",
        "train_3_gram = [n_gram(tokens, 3) for tokens in train_stemmed]\n",
        "test_2_gram = [n_gram(tokens, 2) for tokens in test_stemmed]\n",
        "test_3_gram = [n_gram(tokens, 3) for tokens in test_stemmed]\n",
        "\n",
        "# build the feature list\n",
        "train_feats = list()\n",
        "for i in range(len(x_train)):\n",
        "    train_feats.append(\n",
        "        train_stemmed[i] + train_2_gram[i] + train_3_gram[i])\n",
        "test_feats = list()\n",
        "for i in range(len(x_valid)):\n",
        "    test_feats.append(\n",
        "        test_stemmed[i] + test_2_gram[i] + test_3_gram[i])\n",
        "\n",
        "# build a mapping from features to indices\n",
        "feats_dict = get_feats_dict(\n",
        "    chain.from_iterable(train_feats),\n",
        "    min_freq=5)\n",
        "\n",
        "# build the feats_matrix\n",
        "# convert each example to a ont-hot vector, and then stack vectors as a matrix\n",
        "train_feats_matrix = np.vstack(\n",
        "    [get_onehot_vector(f, feats_dict) for f in train_feats])\n",
        "test_feats_matrix = np.vstack(\n",
        "    [get_onehot_vector(f, feats_dict) for f in test_feats])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpzRHy5-H4hw",
        "outputId": "770b2925-ab51-4976-8b5a-d2a54ed67080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of features: 5802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-30bba320808e>:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  vector = np.zeros(len(feats_dict), dtype=np.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(train_feats_matrix, y_train)\n",
        "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(train_feats_matrix, y_train)\n",
        "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(train_feats_matrix, y_train)\n",
        "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(train_feats_matrix, y_train)"
      ],
      "metadata": {
        "id": "CTOiqffhGedb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(train_feats_matrix, y_train)"
      ],
      "metadata": {
        "id": "srRWeNX1MYqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stepsize in the mesh, it alters the accuracy of the plotprint\n",
        "#to better understand it, just play with the value, change it and print it\n",
        "h = .01\n",
        "#create the mesh\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
        "# create the title that will be shown on the plot\n",
        "titles = ['Linear kernel','RBF kernel','Polynomial kernel','Sigmoid kernel']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "j72tF0rbKrxd",
        "outputId": "5455bdcd-b6f9-4947-9ac6-69a1b4379576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-dcf544ab36f8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#create the mesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, clf in enumerate((linear, rbf, poly, sig)):\n",
        "    #defines how many plots: 2 rows, 2columns=> leading to 4 plots\n",
        "    plt.subplot(2, 2, i + 1) #i+1 is the index\n",
        "    #space between plots\n",
        "    plt.subplots_adjust(wspace=0.4, hspace=0.4) \n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.PuBuGn, alpha=0.7)\n",
        "    # Plot also the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.PuBuGn,     edgecolors='grey')\n",
        "    plt.xlabel('Sepal length')\n",
        "    plt.ylabel('Sepal width')\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.title(titles[i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dx8q6HYwL7_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_pred = linear.predict(test_feats_matrix)\n",
        "poly_pred = poly.predict(test_feats_matrix)\n",
        "rbf_pred = rbf.predict(test_feats_matrix)\n",
        "sig_pred = sig.predict(test_feats_matrix)"
      ],
      "metadata": {
        "id": "MUHaXfFnL_E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the accuracy and print it for all 4 kernel functions\n",
        "accuracy_lin = linear.score(test_feats_matrix, y_valid)\n",
        "accuracy_poly = poly.score(test_feats_matrix, y_valid)\n",
        "accuracy_rbf = rbf.score(test_feats_matrix, y_valid)\n",
        "accuracy_sig = sig.score(test_feats_matrix, y_valid)\n",
        "print('Accuracy Linear Kernel:', accuracy_lin)\n",
        "print(\"Accuracy Polynomial Kernel:\", accuracy_poly)\n",
        "print(\"Accuracy Radial Basis Kernel:\", accuracy_rbf)\n",
        "print('Accuracy Sigmoid Kernel:', accuracy_sig)"
      ],
      "metadata": {
        "id": "wJP2wjNxMAe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Linear Kernel:\\n', classification_report(y_valid, linear_pred))\n",
        "print(\"Polynomial Kernel:\\n\", classification_report(y_valid, poly_pred))\n",
        "print(\"Radial Basis Kernel:\\n\", classification_report(y_valid, rbf_pred))\n",
        "print('Sigmoid Kernel:\\n', classification_report(y_valid, sig_pred))"
      ],
      "metadata": {
        "id": "gkee3gWqOoY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT Base\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/"
      ],
      "metadata": {
        "id": "4-cC9IqaJJP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ91N-rwKjDo",
        "outputId": "74d9b9c6-c02b-4438-c8d0-507d81859c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvtyj_gjznww",
        "outputId": "68627142-d98b-4afd-ee88-730075f31205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "6pagDSGGwZv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "iqsQ80BlwMEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "sosgg4IzKuK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate train data and test data\n",
        "all_reviews = np.concatenate([x_train, x_valid])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_reviews = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_reviews]\n",
        "\n",
        "# Find the maximum length\n",
        "\n",
        "max_len = max([len(sent) for sent in encoded_reviews])\n",
        "'''\n",
        "for sent in encoded_reviews:\n",
        "  if len(sent) == max_len:\n",
        "    print(sent)\n",
        "'''\n",
        "print('Max length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrJqO1CLL34",
        "outputId": "bf04de9b-78df-44d2-897b-722ab9589711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  1155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 512\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([x_train[0]])[0].squeeze().numpy())\n",
        "print('Original: ', x_train[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(x_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(x_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1NUFDcdLONE",
        "outputId": "b69d2ab8-ac79-46b9-d73e-46fe8e93d90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Best Sunday buffet in the two cities of Charlotte and Concord!    Every week they change 80% of the buffet on Sunday so you never get bored.   And the attention to Customer Service was outstanding.    \n",
            "\n",
            "Good for them.  Fresh ingredients and perfect atmosphere.    Loved it. \n",
            "\n",
            "Pat & Ali Hughes\n",
            "Token IDs:  [101, 2190, 4465, 28305, 1999, 1996, 2048, 3655, 1997, 5904, 1998, 16557, 999, 2296, 2733, 2027, 2689, 3770, 1003, 1997, 1996, 28305, 2006, 4465, 2061, 2017, 2196, 2131, 11471, 1012, 1998, 1996, 3086, 2000, 8013, 2326, 2001, 5151, 1012, 2204, 2005, 2068, 1012, 4840, 12760, 1998, 3819, 7224, 1012, 3866, 2009, 1012, 6986, 1004, 4862, 8099, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_valid)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "IWMEtJKYLTiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 5\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD1oZl8Nx2hH",
        "outputId": "6b48c95e-f0f0-41ea-823b-596f0d0577bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 42 s, sys: 0 ns, total: 42 s\n",
            "Wall time: 45.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "metadata": {
        "id": "mo-KzAIByize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "            print(b_input_ids)\n",
        "            print(b_input_ids.shape)\n",
        "            print(b_attn_mask)\n",
        "            print(b_attn_mask.shape)\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "IXKdqmNeyzBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "1zOm7SgtzCQf",
        "outputId": "397cd323-e5ec-49e7-c3f5-35a425bc1052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "tensor([[  101,  1045,  3191,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2031,  ...,     0,     0,     0],\n",
            "        [  101,  1996,  2833,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  1019,  3340,  ...,  2021,  2016,   102],\n",
            "        [  101,  2985,  1037,  ...,     0,     0,     0],\n",
            "        [  101, 17111,  9541,  ...,     0,     0,     0]], device='cuda:0')\n",
            "torch.Size([32, 512])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n",
            "torch.Size([32, 512])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-2578d57f18d0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Set seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-ddc8bed555cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Perform a forward pass. This will return logits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_attn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Compute loss and accumulate the loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 39.56 GiB total capacity; 37.70 GiB already allocated; 196.56 MiB free; 37.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WopsO3-T0pnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZMSn0Hy5UJb"
      },
      "source": [
        "### CNN\n",
        "\n",
        "The second baseline is a CNN model implemented with PyTorch.\n",
        "\n",
        "First, use the following command to install pytorch (in terminal)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n2fiogb5UJc"
      },
      "source": [
        "```bash\n",
        "pip install torch\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70WhNXeX5UJc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWEZApuy5UJc"
      },
      "outputs": [],
      "source": [
        "train_text = train_df['text'].map(tokenize).map(filter_stopwords).map(stem)\n",
        "valid_text = valid_df['text'].map(tokenize).map(filter_stopwords).map(stem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWvH-WcZ5UJc"
      },
      "outputs": [],
      "source": [
        "word2id = {}\n",
        "for tokens in train_text:\n",
        "    for t in tokens:\n",
        "        if not t in word2id:\n",
        "            word2id[t] = len(word2id)\n",
        "word2id['<pad>'] = len(word2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "020Rz3xi5UJc"
      },
      "outputs": [],
      "source": [
        "def texts_to_id_seq(texts, padding_length=500):\n",
        "    records = []\n",
        "    for tokens in texts:\n",
        "        record = []\n",
        "        for t in tokens:\n",
        "            record.append(word2id.get(t, len(word2id)))\n",
        "        if len(record) >= padding_length:\n",
        "            records.append(record[:padding_length])\n",
        "        else:\n",
        "            records.append(record + [word2id['<pad>']] * (padding_length - len(record)))\n",
        "    return records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lT2tV3g5UJc"
      },
      "outputs": [],
      "source": [
        "train_seqs = texts_to_id_seq(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHB6Ud3v5UJd"
      },
      "outputs": [],
      "source": [
        "valid_seqs = texts_to_id_seq(valid_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aubFZ3Mg5UJd"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, seq, y):\n",
        "        assert len(seq) == len(y)\n",
        "        self.seq = seq\n",
        "        self.y = y-1\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return np.asarray(self.seq[idx]), self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1UXP-p15UJd"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(MyDataset(train_seqs, y_train), batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(MyDataset(valid_seqs, y_valid), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPCHEnSB5UJd"
      },
      "outputs": [],
      "source": [
        "class mlp(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mlp, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=len(word2id)+1, embedding_dim=64)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=64,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=3,\n",
        "                      stride=1),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=64,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=3,\n",
        "                      stride=1),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.linear = nn.Linear(64, 5)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = torch.transpose(x, 1, 2)\n",
        "        x = self.cnn(x)\n",
        "        x = torch.max(x, dim=-1)[0]\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niiGxZzO5UJd"
      },
      "outputs": [],
      "source": [
        "model = mlp()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "nZHul4x_5UJe"
      },
      "outputs": [],
      "source": [
        "for e in range(1, 11):    \n",
        "    print('epoch', e)\n",
        "    model.train()\n",
        "    total_acc = 0\n",
        "    total_loss = 0\n",
        "    total_count = 0\n",
        "    with tqdm.tqdm(train_loader) as t:\n",
        "        for x, y in t:\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            total_acc += (logits.argmax(1) == y).sum().item()\n",
        "            total_count += y.size(0)\n",
        "            total_loss += loss.item()\n",
        "            optimizer.step()\n",
        "            t.set_postfix({'loss': total_loss/total_count, 'acc': total_acc/total_count})\n",
        "\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with tqdm.tqdm(valid_loader) as t:\n",
        "        for x, y in t:\n",
        "            logits = model(x)\n",
        "            total_acc += (logits.argmax(1) == y).sum().item()\n",
        "            total_count += len(y)\n",
        "            y_pred += logits.argmax(1).tolist()\n",
        "            y_true += y.tolist()\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"\\n\\n\")\n",
        "    print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2bb-SbT5UJe"
      },
      "source": [
        "Deep learning are full of tricks. \n",
        "\n",
        "In the second example above, the CNN baseline is even not good enough to beat the TFIDF+Logistic regression baseline.\n",
        "\n",
        "You can use all the techniques introduced in the lectures and tutorials to enhance your methods.\n",
        "\n",
        "Of course, you can try any other ideas to make your model distinguished."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}